{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-14T09:58:27.994178Z","iopub.execute_input":"2023-04-14T09:58:27.994767Z","iopub.status.idle":"2023-04-14T09:58:28.031447Z","shell.execute_reply.started":"2023-04-14T09:58:27.994725Z","shell.execute_reply":"2023-04-14T09:58:28.030363Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-internship-20231/train.csv\n/kaggle/input/nlp-internship-20231/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-04-14T09:58:28.033250Z","iopub.execute_input":"2023-04-14T09:58:28.033604Z","iopub.status.idle":"2023-04-14T09:58:30.865252Z","shell.execute_reply.started":"2023-04-14T09:58:28.033559Z","shell.execute_reply":"2023-04-14T09:58:30.864072Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def seed_all(seed_value):\n    random.seed(seed_value) \n    np.random.seed(seed_value) \n    torch.manual_seed(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True \n        torch.backends.cudnn.benchmark = False\n        \nseed = 42\nseed_all(seed)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T09:58:37.654852Z","iopub.execute_input":"2023-04-14T09:58:37.655792Z","iopub.status.idle":"2023-04-14T09:58:37.723454Z","shell.execute_reply.started":"2023-04-14T09:58:37.655749Z","shell.execute_reply":"2023-04-14T09:58:37.722370Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nlp-internship-20231/train.csv')\n# train_df.head(5)\ndata_for_prediction_df = pd.read_csv('/kaggle/input/nlp-internship-20231/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:43:25.152467Z","iopub.execute_input":"2023-04-14T14:43:25.153151Z","iopub.status.idle":"2023-04-14T14:43:25.344310Z","shell.execute_reply.started":"2023-04-14T14:43:25.153113Z","shell.execute_reply":"2023-04-14T14:43:25.343168Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_df['word_len'].hist()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T23:03:26.641325Z","iopub.execute_input":"2023-04-13T23:03:26.641714Z","iopub.status.idle":"2023-04-13T23:03:26.876817Z","shell.execute_reply.started":"2023-04-13T23:03:26.641676Z","shell.execute_reply":"2023-04-13T23:03:26.875464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train_df['lib'])\ntrain_df['label'] = le.transform(train_df['lib'])\n# >>> le.inverse_transform([0, 0, 1, 2])","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:43:27.496924Z","iopub.execute_input":"2023-04-14T14:43:27.497834Z","iopub.status.idle":"2023-04-14T14:43:27.533353Z","shell.execute_reply.started":"2023-04-14T14:43:27.497784Z","shell.execute_reply":"2023-04-14T14:43:27.532407Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"le.classes_","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:35:55.717369Z","iopub.execute_input":"2023-04-14T14:35:55.717753Z","iopub.status.idle":"2023-04-14T14:35:55.725429Z","shell.execute_reply.started":"2023-04-14T14:35:55.717717Z","shell.execute_reply":"2023-04-14T14:35:55.724229Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array(['collections', 'csv', 'datetime', 'django', 'flask', 'functools',\n       'itertools', 'json', 'math', 'matplotlib', 'numpy', 'os', 'pandas',\n       'random', 're', 'requests', 'scipy', 'selenium', 'sklearn',\n       'subprocess', 'sys', 'tensorflow', 'time', 'urllib'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"train_df['title'] = train_df['title'].apply(lambda x: x.lower())\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:43:30.808929Z","iopub.execute_input":"2023-04-14T14:43:30.809682Z","iopub.status.idle":"2023-04-14T14:43:30.870606Z","shell.execute_reply.started":"2023-04-14T14:43:30.809633Z","shell.execute_reply":"2023-04-14T14:43:30.869674Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                                               title        lib      id  label\n0  is there a way to sort strings in alphabetical...  functools   84026      5\n1  maintaining history by soft deleting the row o...     django    8930      3\n2                          wave on a string analysis      numpy  133474     10\n3  regular expression find word but not if it's p...         re   34429     14\n4  textblob - loop over articles to calculate pol...     pandas   82106     12","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>lib</th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>is there a way to sort strings in alphabetical...</td>\n      <td>functools</td>\n      <td>84026</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>maintaining history by soft deleting the row o...</td>\n      <td>django</td>\n      <td>8930</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>wave on a string analysis</td>\n      <td>numpy</td>\n      <td>133474</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>regular expression find word but not if it's p...</td>\n      <td>re</td>\n      <td>34429</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>textblob - loop over articles to calculate pol...</td>\n      <td>pandas</td>\n      <td>82106</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# for c in le.classes_:\nlibs = pd.DataFrame(np.vstack(train_df['title'].apply(lambda x: \\\n        [1 if c in x.split(' ') else 0 for c in le.classes_]).values), columns=le.classes_)\ntrain_df = pd.concat((train_df, libs), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:43:33.228087Z","iopub.execute_input":"2023-04-14T14:43:33.228828Z","iopub.status.idle":"2023-04-14T14:43:36.252960Z","shell.execute_reply.started":"2023-04-14T14:43:33.228789Z","shell.execute_reply":"2023-04-14T14:43:36.251938Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['datetime'] == 1]","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:43:43.112860Z","iopub.execute_input":"2023-04-14T14:43:43.113232Z","iopub.status.idle":"2023-04-14T14:43:43.156240Z","shell.execute_reply.started":"2023-04-14T14:43:43.113198Z","shell.execute_reply":"2023-04-14T14:43:43.155097Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"                                                    title       lib      id  \\\n67      how to add arrow annotations with an offset to...    pandas   46764   \n70       convert timestamp string date to datetime python    pandas   43422   \n220     generate offsets for each row in a dataframe b...    pandas   78905   \n616       how to append gmt+ to datetime object in python  datetime    5072   \n858                      sub-class python datetime object  datetime   12883   \n...                                                   ...       ...     ...   \n133288               flagging overlapping datetime ranges  datetime  116777   \n133499     merge datetime series to multi-index dataframe     numpy   26661   \n133513  comparing a datetime dataframe with a period d...    pandas   78703   \n133834  extract time from datetime object and compare ...  datetime   32429   \n133849  finding the year and quarter from a datetime o...  datetime  174206   \n\n        label  collections  csv  datetime  django  flask  functools  ...  re  \\\n67         12            0    0         1       0      0          0  ...   0   \n70         12            0    0         1       0      0          0  ...   0   \n220        12            0    0         1       0      0          0  ...   0   \n616         2            0    0         1       0      0          0  ...   0   \n858         2            0    0         1       0      0          0  ...   0   \n...       ...          ...  ...       ...     ...    ...        ...  ...  ..   \n133288      2            0    0         1       0      0          0  ...   0   \n133499     10            0    0         1       0      0          0  ...   0   \n133513     12            0    0         1       0      0          0  ...   0   \n133834      2            0    0         1       0      0          0  ...   0   \n133849      2            0    0         1       0      0          0  ...   0   \n\n        requests  scipy  selenium  sklearn  subprocess  sys  tensorflow  time  \\\n67             0      0         0        0           0    0           0     0   \n70             0      0         0        0           0    0           0     0   \n220            0      0         0        0           0    0           0     0   \n616            0      0         0        0           0    0           0     0   \n858            0      0         0        0           0    0           0     0   \n...          ...    ...       ...      ...         ...  ...         ...   ...   \n133288         0      0         0        0           0    0           0     0   \n133499         0      0         0        0           0    0           0     0   \n133513         0      0         0        0           0    0           0     0   \n133834         0      0         0        0           0    0           0     1   \n133849         0      0         0        0           0    0           0     0   \n\n        urllib  \n67           0  \n70           0  \n220          0  \n616          0  \n858          0  \n...        ...  \n133288       0  \n133499       0  \n133513       0  \n133834       0  \n133849       0  \n\n[1079 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>lib</th>\n      <th>id</th>\n      <th>label</th>\n      <th>collections</th>\n      <th>csv</th>\n      <th>datetime</th>\n      <th>django</th>\n      <th>flask</th>\n      <th>functools</th>\n      <th>...</th>\n      <th>re</th>\n      <th>requests</th>\n      <th>scipy</th>\n      <th>selenium</th>\n      <th>sklearn</th>\n      <th>subprocess</th>\n      <th>sys</th>\n      <th>tensorflow</th>\n      <th>time</th>\n      <th>urllib</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>67</th>\n      <td>how to add arrow annotations with an offset to...</td>\n      <td>pandas</td>\n      <td>46764</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>convert timestamp string date to datetime python</td>\n      <td>pandas</td>\n      <td>43422</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>generate offsets for each row in a dataframe b...</td>\n      <td>pandas</td>\n      <td>78905</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>616</th>\n      <td>how to append gmt+ to datetime object in python</td>\n      <td>datetime</td>\n      <td>5072</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>sub-class python datetime object</td>\n      <td>datetime</td>\n      <td>12883</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>133288</th>\n      <td>flagging overlapping datetime ranges</td>\n      <td>datetime</td>\n      <td>116777</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>133499</th>\n      <td>merge datetime series to multi-index dataframe</td>\n      <td>numpy</td>\n      <td>26661</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>133513</th>\n      <td>comparing a datetime dataframe with a period d...</td>\n      <td>pandas</td>\n      <td>78703</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>133834</th>\n      <td>extract time from datetime object and compare ...</td>\n      <td>datetime</td>\n      <td>32429</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>133849</th>\n      <td>finding the year and quarter from a datetime o...</td>\n      <td>datetime</td>\n      <td>174206</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1079 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# train_df = train_df.sample(10000)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T22:34:49.449579Z","iopub.execute_input":"2023-04-13T22:34:49.449950Z","iopub.status.idle":"2023-04-13T22:34:49.485427Z","shell.execute_reply.started":"2023-04-13T22:34:49.449918Z","shell.execute_reply":"2023-04-13T22:34:49.484442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NN","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:00:08.123199Z","iopub.execute_input":"2023-04-11T15:00:08.123951Z","iopub.status.idle":"2023-04-11T15:00:08.187710Z","shell.execute_reply.started":"2023-04-11T15:00:08.123898Z","shell.execute_reply":"2023-04-11T15:00:08.186260Z"}}},{"cell_type":"code","source":"from transformers import BertModel, BertTokenizer, AdamW,  get_linear_schedule_with_warmup, set_seed\nfrom transformers import DistilBertTokenizer, DistilBertModel\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader , Dataset\nimport torch.nn as nn \nimport torch\nimport numpy as np\nfrom sklearn.metrics import f1_score, precision_score\nfrom sklearn.model_selection import StratifiedKFold\nimport random\n\nimport glob\nimport os\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-04-14T10:10:57.203210Z","iopub.execute_input":"2023-04-14T10:10:57.204405Z","iopub.status.idle":"2023-04-14T10:11:06.351418Z","shell.execute_reply.started":"2023-04-14T10:10:57.204357Z","shell.execute_reply":"2023-04-14T10:11:06.350268Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ModelConfig:\n    NB_EPOCHS = 5\n    LR = 3e-5\n    EPS = 1e-8\n    MAX_LEN = 32\n    N_SPLITS = 4\n    TRAIN_BS = 64\n    VALID_BS = 32\n#     MODEL_NAME = 'cointegrated/rubert-tiny-sentiment-balanced'\n#     TOKENIZER = BertTokenizer.from_pretrained('cointegrated/rubert-tiny-sentiment-balanced')\n    MODEL_NAME = 'nbroad/ESG-BERT'\n    TOKENIZER = BertTokenizer.from_pretrained('nbroad/ESG-BERT')\n#     MODEL_NAME = 'carrassi-ni/bert-base-trec-question-classification'\n#     TOKENIZER = BertTokenizer.from_pretrained('carrassi-ni/bert-base-trec-question-classification')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T12:18:01.187479Z","iopub.execute_input":"2023-04-14T12:18:01.188178Z","iopub.status.idle":"2023-04-14T12:18:01.374472Z","shell.execute_reply.started":"2023-04-14T12:18:01.188138Z","shell.execute_reply":"2023-04-14T12:18:01.373286Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"n_labels = len(train_df['label'].value_counts())\nmodel = LibClassifier(n_labels)\nmodel.cuda()\npass\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# train(model, train_data, test_data, ModelConfig.NB_EPOCHS, device, 'final_model')\n# pickle.dump(model, open('final_model.sav', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:59:45.319897Z","iopub.execute_input":"2023-04-14T14:59:45.320260Z","iopub.status.idle":"2023-04-14T14:59:46.823825Z","shell.execute_reply.started":"2023-04-14T14:59:45.320227Z","shell.execute_reply":"2023-04-14T14:59:46.822812Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at nbroad/ESG-BERT were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"class LibDataset(Dataset):\n    def __init__(self, texts, targets=None, le_classes=None, n_classes=24, is_test=False):\n        self.texts = texts\n        self.targets = targets\n        self.le_classes = le_classes\n        self.n_classes = n_classes\n        self.is_test = is_test\n        self.tokenizer = ModelConfig.TOKENIZER\n        self.max_len = ModelConfig.MAX_LEN\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        text = ' '.join(text.split())\n       \n        inputs = self.tokenizer(\n                            text,\n                            add_special_tokens=True,\n                            max_length=self.max_len,\n                            padding=\"max_length\" ,\n                            truncation = True ,\n                            pad_to_max_length=True, \n                            )\n        \n        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n#         token_type = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n     \n        le_classes = torch.tensor(self.le_classes[idx], dtype=torch.float32)\n        if self.is_test:\n            \n            return {\n                'ids': ids,\n                'mask': mask,\n                'le_classes': le_classes\n#                 'token_type': token_type,\n            }\n        else:    \n#             one_hot = F.one_hot(torch.tensor(self.targets[idx], dtype=torch.long), self.n_classes)\n            targets = torch.tensor(self.targets[idx], dtype=torch.long)\n            return {\n                'ids': ids,\n                'mask': mask,\n                'le_classes': le_classes,\n#                 'token_type': token_type,\n                'targets': targets\n            }\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:02:20.686966Z","iopub.execute_input":"2023-04-14T15:02:20.687700Z","iopub.status.idle":"2023-04-14T15:02:20.698732Z","shell.execute_reply.started":"2023-04-14T15:02:20.687637Z","shell.execute_reply":"2023-04-14T15:02:20.697431Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# train_df[le.classes_]","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:56:49.031562Z","iopub.execute_input":"2023-04-14T14:56:49.032290Z","iopub.status.idle":"2023-04-14T14:56:49.036886Z","shell.execute_reply.started":"2023-04-14T14:56:49.032253Z","shell.execute_reply":"2023-04-14T14:56:49.035685Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"def LibDataloader(df, le_classes, batch_size, is_test=False, n_classes=24):\n    dataset = LibDataset(texts=df[\"title\"].values,\n                         targets=df[\"label\"].values,\n                         le_classes=df[le_classes].values,\n                         is_test=False,\n                         n_classes = n_classes)\n    dataloader = DataLoader(dataset, batch_size, shuffle=False)\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:06:38.441552Z","iopub.execute_input":"2023-04-14T16:06:38.442256Z","iopub.status.idle":"2023-04-14T16:06:38.448217Z","shell.execute_reply.started":"2023-04-14T16:06:38.442217Z","shell.execute_reply":"2023-04-14T16:06:38.447195Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"class LibClassifier(nn.Module):\n    def __init__(self, n_classes):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(ModelConfig.MODEL_NAME, return_dict=False)\n        self.drop = nn.Dropout(p=0.5)\n        \n        self.fc1 = nn.Linear(24, 768)\n        self.drop1 = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(768, 768)\n        self.out = nn.Linear(1536, n_classes)\n        \n        \n    def forward(self, input_ids, attention_mask, le_classes):\n        \n        _, output = self.bert(input_ids, attention_mask)\n#         print(output)\n        output = self.drop(output)\n        \n        output_2 = self.fc1(le_classes)\n        output_2 = self.drop1(output_2)\n        output_2 = self.fc2(output_2)\n        \n        output = torch.cat((output, output_2), 1)\n        output = self.out(output)\n    \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:05:20.636742Z","iopub.execute_input":"2023-04-14T15:05:20.637453Z","iopub.status.idle":"2023-04-14T15:05:20.645699Z","shell.execute_reply.started":"2023-04-14T15:05:20.637415Z","shell.execute_reply":"2023-04-14T15:05:20.644393Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"n_labels = len(train_df['label'].value_counts())\nprint(n_labels)\nmodel = LibClassifier(n_labels)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T10:11:45.477796Z","iopub.execute_input":"2023-04-14T10:11:45.478180Z","iopub.status.idle":"2023-04-14T10:11:49.373920Z","shell.execute_reply.started":"2023-04-14T10:11:45.478145Z","shell.execute_reply":"2023-04-14T10:11:49.372929Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"24\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/2.67k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"290f238096e54d39b9d254fe81f4a15b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d5c6cd534d44a2ab65b784fb58f6c3"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at nbroad/ESG-BERT were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"def loss_fn(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)\n\ndef precision_micro(outputs, targets):\n    pred = np.argmax(outputs.cpu().detach().numpy(), axis=1).flatten()\n    targets = targets.cpu().detach().numpy()\n    return precision_score(pred, targets, average='micro')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T10:11:52.018097Z","iopub.execute_input":"2023-04-14T10:11:52.019002Z","iopub.status.idle":"2023-04-14T10:11:52.026080Z","shell.execute_reply.started":"2023-04-14T10:11:52.018948Z","shell.execute_reply":"2023-04-14T10:11:52.024586Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def yield_optimizer(model):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n\n    optimizer_parameters = [\n        {\n            \"params\": [\n                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.001,\n        },\n        {\n            \"params\": [\n                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.0,\n        },\n    ]\n    return torch.optim.AdamW(optimizer_parameters, lr=ModelConfig.LR, eps=ModelConfig.EPS) ","metadata":{"execution":{"iopub.status.busy":"2023-04-14T10:11:54.200572Z","iopub.execute_input":"2023-04-14T10:11:54.201531Z","iopub.status.idle":"2023-04-14T10:11:54.209544Z","shell.execute_reply.started":"2023-04-14T10:11:54.201481Z","shell.execute_reply":"2023-04-14T10:11:54.208197Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n    model.train()\n    losses = []\n    correct_predictions = []\n\n    for step , d in enumerate(data_loader):\n        input_ids = d['ids'].to(device) \n#         token_type_ids = d['token_type'].to(device)\n        attention_mask = d['mask'].to(device)\n        targets = d['targets'].to(device)\n        le_classes = d['le_classes'].to(device)\n        outputs = model(\n            input_ids ,\n            attention_mask ,\n            le_classes\n#             token_type_ids,\n            )\n        \n        loss = loss_fn(outputs, targets)\n        correct_predictions.append(precision_micro(outputs, targets))\n        losses.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n        \n    return np.mean(correct_predictions, axis=0), np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:05:04.726977Z","iopub.execute_input":"2023-04-14T15:05:04.727711Z","iopub.status.idle":"2023-04-14T15:05:04.736099Z","shell.execute_reply.started":"2023-04-14T15:05:04.727669Z","shell.execute_reply":"2023-04-14T15:05:04.734734Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"def eval_model (model, data_loader, loss_fn, device, n_examples):\n    model.eval()\n  \n    losses = []\n    correct_predictions = []\n\n    with torch.no_grad():\n        for step , d in enumerate(data_loader):\n            \n            input_ids = d['ids'].to(device)\n#             token_type_ids = d['token_type'].to(device)\n            attention_mask = d['mask'].to(device)\n            le_classes = d['le_classes'].to(device)\n            targets = d['targets'].to(device)\n        \n            outputs = model(\n                   input_ids ,\n                attention_mask ,\n                le_classes\n#                 token_type_ids,\n                )\n\n            loss = loss_fn(outputs , targets)\n            correct_predictions.append(precision_micro(outputs, targets))\n            losses.append(loss.item())\n\n    return np.mean(correct_predictions, axis=0), np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:11:12.652732Z","iopub.execute_input":"2023-04-14T15:11:12.653097Z","iopub.status.idle":"2023-04-14T15:11:12.663556Z","shell.execute_reply.started":"2023-04-14T15:11:12.653065Z","shell.execute_reply":"2023-04-14T15:11:12.662492Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T20:05:01.232343Z","iopub.execute_input":"2023-04-13T20:05:01.232827Z","iopub.status.idle":"2023-04-13T20:05:01.254085Z","shell.execute_reply.started":"2023-04-13T20:05:01.232782Z","shell.execute_reply":"2023-04-13T20:05:01.253097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, df, test_df, epochs, device, model_name):\n    best_accuracy = 0\n    \n    test_data_loader = LibDataloader(test_df, ModelConfig.VALID_BS)\n    \n    for epoch in range(epochs):\n        # if epoch % 10 == 0:\n        print(f'Epoch {epoch + 1}')\n\n        kf = StratifiedKFold(n_splits=ModelConfig.N_SPLITS, random_state=seed, shuffle=True)\n\n        for step, (train, valid ) in enumerate(kf.split(df , df[\"label\"])) :\n\n            train_data_loader = LibDataloader(df.iloc[train], ModelConfig.TRAIN_BS)\n            validation_data_loader = LibDataloader(df.iloc[valid], ModelConfig.VALID_BS)\n\n            nb_train_steps = int(len(train_data_loader) / ModelConfig.TRAIN_BS * epochs)\n            optimizer = yield_optimizer(model)\n            scheduler = get_linear_schedule_with_warmup(\n                                        optimizer,\n                                        num_warmup_steps=0,\n                                        num_training_steps=nb_train_steps)\n\n            train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(df.iloc[train])) \n            val_acc, val_loss = eval_model(model, validation_data_loader, loss_fn, device, len(df.iloc[valid]))\n\n            test_acc, _ = eval_model(model, test_data_loader, loss_fn, device, len(test_df))\n            \n            if  test_acc > best_accuracy:\n                torch.save(model.state_dict(), model_name + '.bin')\n                best_accuracy = test_acc\n                print(f\"Best accuracy {best_accuracy}\")\n            \n            \n            \n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T12:18:26.669147Z","iopub.execute_input":"2023-04-14T12:18:26.669506Z","iopub.status.idle":"2023-04-14T12:18:26.680109Z","shell.execute_reply.started":"2023-04-14T12:18:26.669472Z","shell.execute_reply":"2023-04-14T12:18:26.678927Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data, test_data = train_test_split(train_df, train_size=0.9, stratify=train_df['label'])\n# train_data, val_data = train_test_split(train_data, train_size=0.9, stratify=train_data['label'])","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:03:17.922443Z","iopub.execute_input":"2023-04-14T15:03:17.923171Z","iopub.status.idle":"2023-04-14T15:03:18.018990Z","shell.execute_reply.started":"2023-04-14T15:03:17.923131Z","shell.execute_reply":"2023-04-14T15:03:18.017935Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"n_labels = len(train_df['label'].value_counts())\nmodel = LibClassifier(n_labels)\nmodel.cuda()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain(model, train_data, test_data, 4, device, 'final_model')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:13:14.067740Z","iopub.execute_input":"2023-04-14T15:13:14.068450Z","iopub.status.idle":"2023-04-14T16:02:20.783971Z","shell.execute_reply.started":"2023-04-14T15:13:14.068412Z","shell.execute_reply":"2023-04-14T16:02:20.781934Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at nbroad/ESG-BERT were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1\nBest accuracy 0.34363674533722266\nBest accuracy 0.4476929196499602\nBest accuracy 0.4947212277910369\nBest accuracy 0.5161677936886767\nEpoch 2\nBest accuracy 0.5259380800848581\nBest accuracy 0.5366641253425263\nBest accuracy 0.540942941748431\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1858910490.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/1609427438.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, df, test_df, epochs, device, model_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m                                         num_training_steps=nb_train_steps)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1080913144.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m                   \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                   \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                   capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    230\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'final_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:02:36.315840Z","iopub.execute_input":"2023-04-14T16:02:36.316900Z","iopub.status.idle":"2023-04-14T16:02:37.234267Z","shell.execute_reply.started":"2023-04-14T16:02:36.316858Z","shell.execute_reply":"2023-04-14T16:02:37.233121Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'final_model.bin')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:03:28.291762Z","iopub.execute_input":"2023-04-14T16:03:28.292127Z","iopub.status.idle":"2023-04-14T16:03:28.299116Z","shell.execute_reply.started":"2023-04-14T16:03:28.292089Z","shell.execute_reply":"2023-04-14T16:03:28.297896Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/final_model.bin","text/html":"<a href='final_model.bin' target='_blank'>final_model.bin</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef get_predictions(model, df, le_classes):\n    proba = []    \n    model = model.eval()\n\n    predictions = []\n\n    test_data_loader = LibDataloader(df, le_classes, 1)\n    with torch.no_grad():\n        for d in tqdm(test_data_loader):\n            \n            input_ids = d[\"ids\"].to(device)\n            attention_mask = d[\"mask\"].to(device)\n            le_classes = d['le_classes'].to(device)\n            outputs = model(\n                            input_ids,\n                            attention_mask ,\n                            le_classes\n                            )\n            proba.append(torch.argmax(outputs).flatten().cpu().numpy())\n    return np.array(proba).flatten()","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:05:19.873327Z","iopub.execute_input":"2023-04-14T16:05:19.873718Z","iopub.status.idle":"2023-04-14T16:05:19.881739Z","shell.execute_reply.started":"2023-04-14T16:05:19.873677Z","shell.execute_reply":"2023-04-14T16:05:19.880710Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(df, le):\n    df['title'] = df['title'].apply(lambda x: x.lower())\n    df = df.dropna()\n    libs = pd.DataFrame(np.vstack(df['title'].apply(lambda x: \\\n        [1 if c in x.split(' ') else 0 for c in le.classes_]).values), columns=le.classes_)\n    df = pd.concat((df, libs), axis=1)\n    df['sym_len'] = df['title'].apply(len)\n    df['word_len'] = df['title'].apply(lambda x: len(x.split()))\n    return df\n\nfor_prediction_df = pd.read_csv('/kaggle/input/nlp-internship-20231/test.csv')\nfor_prediction_df = preprocess_data(for_prediction_df, le)\nfor_prediction_df['label'] = -1","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:04:33.819437Z","iopub.execute_input":"2023-04-14T16:04:33.819821Z","iopub.status.idle":"2023-04-14T16:04:34.642454Z","shell.execute_reply.started":"2023-04-14T16:04:33.819788Z","shell.execute_reply":"2023-04-14T16:04:34.641411Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"sample_submission = for_prediction_df[['id']]\nsample_submission['lib'] = le.inverse_transform(get_predictions(model, for_prediction_df, le.classes_))\nsample_submission.to_csv('./submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:08:07.039785Z","iopub.execute_input":"2023-04-14T16:08:07.040159Z","iopub.status.idle":"2023-04-14T16:12:40.024015Z","shell.execute_reply.started":"2023-04-14T16:08:07.040120Z","shell.execute_reply":"2023-04-14T16:12:40.023037Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stderr","text":"100%|██████████| 33506/33506 [04:32<00:00, 122.79it/s]\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'./submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:13:28.940670Z","iopub.execute_input":"2023-04-14T16:13:28.941637Z","iopub.status.idle":"2023-04-14T16:13:28.948757Z","shell.execute_reply.started":"2023-04-14T16:13:28.941599Z","shell.execute_reply":"2023-04-14T16:13:28.947716Z"},"trusted":true},"execution_count":139,"outputs":[{"execution_count":139,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='./submission.csv' target='_blank'>./submission.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"# def TestDataloader(df, batch_size, is_test=True):\n#     dataset = LibDataset(df, is_test)\n#     dataloader = DataLoader(dataset, batch_size, shuffle=False)\n#     return dataloader\n\ndef get_raw_predictions(model, df):\n    proba = []    \n    model = model.eval()\n\n\n    test_data_loader = LibDataloader(df, 1)\n    with torch.no_grad():\n        for d in test_data_loader:\n            \n            input_ids = d[\"ids\"].to(device)\n            attention_mask = d[\"mask\"].to(device)\n            \n            outputs = model(\n                            input_ids,\n                            attention_mask ,\n                            )\n            proba.append(outputs[0].cpu().numpy())\n    return np.array(proba)\n\ndef get_predictions(model, df):\n    proba = []    \n    model = model.eval()\n\n    predictions = []\n\n#     data_loader = TestDataloader(df, 1)\n    test_data_loader = LibDataloader(df, 1)\n    with torch.no_grad():\n        for d in test_data_loader:\n            \n            input_ids = d[\"ids\"].to(device)\n            attention_mask = d[\"mask\"].to(device)\n#             token_type_ids = d[\"token_type\"].to(device)\n            \n            outputs = model(\n                            input_ids,\n                            attention_mask ,\n#                             token_type_ids\n                            )\n            proba.append(torch.argmax(outputs).flatten().cpu().numpy())\n    return np.array(proba).flatten()\n\n# preds = get_predictions(model, test_data)\n\n# print(classification_report(test_data['label'], preds))","metadata":{"execution":{"iopub.status.busy":"2023-04-14T14:46:56.559162Z","iopub.execute_input":"2023-04-14T14:46:56.559523Z","iopub.status.idle":"2023-04-14T14:46:56.570057Z","shell.execute_reply.started":"2023-04-14T14:46:56.559490Z","shell.execute_reply":"2023-04-14T14:46:56.568611Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(test_data['label'], preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()\nfig = disp.ax_.get_figure() \nfig.set_figwidth(10)\nfig.set_figheight(10) ","metadata":{"execution":{"iopub.status.busy":"2023-04-14T00:45:37.361454Z","iopub.execute_input":"2023-04-14T00:45:37.361966Z","iopub.status.idle":"2023-04-14T00:45:40.157135Z","shell.execute_reply.started":"2023-04-14T00:45:37.361915Z","shell.execute_reply":"2023-04-14T00:45:40.156086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\npickle.dump(model, open('final_model.sav', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T22:59:41.693314Z","iopub.execute_input":"2023-04-13T22:59:41.694019Z","iopub.status.idle":"2023-04-13T22:59:42.522020Z","shell.execute_reply.started":"2023-04-13T22:59:41.693983Z","shell.execute_reply":"2023-04-13T22:59:42.520506Z"},"trusted":true},"execution_count":null,"outputs":[]}]}